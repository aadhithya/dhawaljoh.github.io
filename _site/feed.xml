<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <description>Geek, foodie, dilettante.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 15 Dec 2019 21:39:53 -0800</pubDate>
    <lastBuildDate>Sun, 15 Dec 2019 21:39:53 -0800</lastBuildDate>
    <generator>Jekyll v3.8.6</generator>
    
      <item>
        <title>What is Lorem Ipsum?</title>
        <description>&lt;p&gt;Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry’s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.&lt;/p&gt;

&lt;h3 id=&quot;where-does-it-come-from&quot;&gt;Where does it come from?&lt;/h3&gt;

&lt;p&gt;Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of “de Finibus Bonorum et Malorum” (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, “Lorem ipsum dolor sit amet..”, comes from a line in section 1.10.32.&lt;/p&gt;

&lt;p&gt;The standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from “de Finibus Bonorum et Malorum” by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham.&lt;/p&gt;

&lt;h3 id=&quot;why-do-we-use-it&quot;&gt;Why do we use it?&lt;/h3&gt;

&lt;p&gt;It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to using ‘Content here, content here’, making it look like readable English. Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text, and a search for ‘lorem ipsum’ will uncover many web sites still in their infancy. Various versions have evolved over the years, sometimes by accident, sometimes on purpose (injected humour and the like).&lt;/p&gt;

&lt;h3 id=&quot;where-can-i-get-some&quot;&gt;Where can I get some?&lt;/h3&gt;

&lt;p&gt;There are many variations of passages of Lorem Ipsum available, but the majority have suffered alteration in some form, by injected humour, or randomised words which don’t look even slightly believable. If you are going to use a passage of Lorem Ipsum, you need to be sure there isn’t anything embarrassing hidden in the middle of text. All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary, making this the first true generator on the Internet. It uses a dictionary of over 200 Latin words, combined with a handful of model sentence structures, to generate Lorem Ipsum which looks reasonable. The generated Lorem Ipsum is therefore always free from repetition, injected humour, or non-characteristic words etc.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This content was copied from http://www.lipsum.com/ as an example of post article.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Sun, 15 Dec 2019 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2019/what-is-lorem-ipsum/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/what-is-lorem-ipsum/</guid>
        
        
      </item>
    
      <item>
        <title>Projects</title>
        <description>&lt;ul style=&quot;text-align: justify;&quot;&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;/files/MS.pdf&quot; target=&quot;_blank&quot;&gt;Master’s Project: User Expertise Detection in Online Communities&lt;/a&gt;&lt;/strong&gt;: [Summer, Fall 18’] &lt;br /&gt;
While detection of experts in online communities is a widely studied problem, most work fail to incorporate the inherent relational nature of these online communities. In this work, we explore the usage of the linkages that exist between posts and be- tween users (structure) in these community question answering sites in the form of related posts, duplicate posts, etc. and use this relational structure in conjunction with local information to collectively predict users’ expertise. We compare the statistics of the evaluation tests to the baseline results from related works to measure the performance of our approach compared to the non-relational methods. We see that using the relational structure of the data helps outperform baseline methods.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&quot;text-align: justify;&quot;&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;/files/203-final-report.pdf&quot; target=&quot;_blank&quot;&gt;Data Programming: A New Paradigm For Unlabelled Data&lt;/a&gt;&lt;/strong&gt;: [CMPS203, Spring 18’] &lt;br /&gt;
This is a survey on the recent progress in the improvement of data labelling processes. I study the newly introduced “Data Pro- gramming”, a paradigm which deals with programmatic creation of datasets. Then, I look at “Snorkel”, a system that allows users to train models without hand labelling any data. The users can write labelling functions representing heuristics to label data, and can vary in coverages and accuracies. “Snorkel” denoises their outputs and combines them to provide probabilistic data labels. Then, I study “Babble Labble”, which is an extension built using Snorkel, that processes heuristics described in natural language to labelling functions and thereby used to label data. These works constitute an important foray in this space of data labelling, and is right on the horizon of the massive data wave currently under way.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&quot;text-align: justify;&quot;&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;/files/cmps-290-spring.pdf&quot; target=&quot;_blank&quot;&gt;Effects of Social Influences on Culinary Preferences&lt;/a&gt;&lt;/strong&gt;: [CMPS290C, Spring 17’] &lt;br /&gt;
Higgs et al., hypothesize that an individuals’ eating behaviour is strongly influenced by social context. In this work, we seek to model the influence of a friend network on the culinary choices of individuals. We predict a person’s favorite cuisine from social influences from their network and evaluate our model by comparing our predictions to the gold labels that are extracted from the text of the reviews. We use the data from the “Yelp Dataset Challenge” dataset.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&quot;text-align: justify;&quot;&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;/files/cmps-245-winter.pdf&quot; target=&quot;_blank&quot;&gt;Ideology-Backed Stance Classification&lt;/a&gt;&lt;/strong&gt;: [CMPS245, Winter 17’] &lt;br /&gt;
The determination of stance in two-sided discussions/debates in online debate forums is a new and interesting problem in opinion mining. We target the task of classifying stance in ideological debates on online debate forums,
and this is a rather challenging problem due to the nature of debate setting and the language used. Previous work has introduced the notion of using ideology as an inter-post, extra-linguistic constraint which are implemented using Integer Linear Programming. In this work, we seek to improve an approach on jointly-modeling disagreement and stance in online debate forums by integrating ideology as a latent variable in the joint model. We show improvement of a few percentage points over the baselines set by prior works. Additionally, we have also created a new ideology corpus of around 1.5 million tweets by 645 official members of the U.S. Congress.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&quot;text-align: justify;&quot;&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;/files/standoff-evolutionary-analysis.pdf&quot; target=&quot;_blank&quot;&gt;Standoff: An Evolutionary Analysis&lt;/a&gt;&lt;/strong&gt;: [CMPS272, Winter 17’] [&lt;a href=&quot;https://bitbucket.org/dhawaljoh/standoff-gametheory-272&quot; target=&quot;_blank&quot;&gt;code&lt;/a&gt;]&lt;br /&gt;
This work is an equilibrium analysis of Standoff, a stochastic game involving simultaneous move stages with state transitions. Players must decide their best response dependent upon their state, the states of the opposing players, and the states of players in the succeeding stage. In order to analyze Standoff, we constructed strategic form stage diagrams, bi-matrices for two- and three-player versions of Standoff, and determined a mixed strategy per stage of the game. To win, each player should make decisions in a manner that maximizes the probability of being the last man standing. A winning strategy is a complete action plan, which specifies a decision at each stage considering the state combination. Our analysis finds a symmetric equilibrium strategy at a given stage and uses evolutionary dynamics to ascertain the stability of our equilibrium.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&quot;text-align: justify;&quot;&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;/files/242-final-report.pdf&quot; target=&quot;_blank&quot;&gt;Detecting Competitors in a New Location for Yelp Businesses&lt;/a&gt;&lt;/strong&gt;: [CMPS242, Fall 16’] [&lt;a href=&quot;https://github.com/eriq-augustine/242-2016&quot; target=&quot;_blank&quot;&gt;code&lt;/a&gt;] &lt;br /&gt;
Our project is focused around helping business owners find potential competitors if they choose to open a branch in a new location. Using this information the business owners can not only find potential competitors, but also get an idea of how well their business will be received in the new locality. We say that a “competitor” is any similar business, with the idea that a similar business caters to a similar clientele and is therefore a competitor. Therefore our task involves finding similar businesses in other regions. We do this by first clustering similar businesses. Once we have the clusters, to find similar businesses in a location, we look into the cluster to which a given restaurant belongs to, and then display restaurants in that cluster that are close to the location. We use the k-medoids algorithm to cluster the businesses as not all attributes are numeric in nature and we need a richer set of dissimilarity scores. We run experiments with various parameter settings, dissimilarity scores, and features and report the rand index on a “gold standard” data set.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&quot;text-align: justify;&quot;&gt;
  &lt;li&gt;&lt;strong&gt;Analysis of clinical notes of ICU patients using Topic Models&lt;/strong&gt;: [Work done at XRCI, IISc with &lt;em&gt;&lt;a class=&quot;tosu&quot; href=&quot;https://sites.google.com/site/vaibhavrajan/&quot; target=&quot;_blank&quot;&gt;Dr. Vaibhav Rajan&lt;/a&gt;&lt;/em&gt;] &lt;br /&gt;
Worked on predictive health-care using unstructured nursing notes by looking at temporal evolutions of topic proportions generated via Topic Modeling.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&quot;text-align: justify;&quot;&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;/files/openday2015.pdf&quot; target=&quot;_blank&quot;&gt;Temporal Scoping of Relational Facts in a Knowledge Base&lt;/a&gt;&lt;/strong&gt;: [Work done at SERC, IISc with &lt;em&gt;&lt;a class=&quot;tosu&quot; href=&quot;http://www.talukdar.net/&quot; target=&quot;_blank&quot;&gt;Prof. Partha Talukdar&lt;/a&gt;&lt;/em&gt;] &lt;br /&gt;
To identify if a relation existed between two entities in a sentence, we constructed a model consisting of n-grams which provided clues for the relation. These n-grams, along with features from Entity Linking were used to train a GBDT to identify relations. Stanford’s SUTime was used to extract temporal information present and then normalized. Triggers chosen manually from the language model were used to indicate the start or end of relationships. We devised an algorithm to update the start/end times iteratively as more temporal information was found through new sentences.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&quot;text-align: justify;&quot;&gt;
  &lt;li&gt;&lt;strong&gt;Automatic Driver Behaviour Profiling&lt;/strong&gt;: [Work done at CSE, IIT Kharagpur with &lt;em&gt;&lt;a class=&quot;tosu&quot; href=&quot;http://www.facweb.iitkgp.ernet.in/~sudeshna/&quot; target=&quot;_blank&quot;&gt;Prof. Sudeshna Sarkar&lt;/a&gt;&lt;/em&gt;] [&lt;a href=&quot;https://github.com/dhawaljoh/IIT-Kharagpur&quot; target=&quot;_blank&quot;&gt;code&lt;/a&gt;] &lt;br /&gt;
Worked on profiling the driving patterns of various drivers using GPS data of trucks across India over 15 years using GPS dataset provided by MHRD. Some preliminary data munging and visualizations were done to understand the spread of data. Detection of hotspots(stoppage areas, resting places) using DBSCAN algorithm and road segmentation based on their speed profiles was also done. I also modified the “simplekml” module to plot the GPS points on Google Maps.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&quot;text-align: justify;&quot;&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://ltrc.iiit.ac.in/icon2015/icon2015_proceedings/PDF/04_rp.pdf&quot; target=&quot;_blank&quot;&gt;Craigslist Post Classifier: Identify the Category&lt;/a&gt;&lt;/strong&gt;: [&lt;a href=&quot;https://github.com/dhawaljoh/craigslist_category_classification&quot; target=&quot;_blank&quot;&gt;code&lt;/a&gt;] &lt;br /&gt;
Used bag of words model, tf-idf and SVM to classify posts on Craigslist into sections based on the product description. The open dataset was available on HackerRank. &lt;strong&gt;Accuracy&lt;/strong&gt;: 81%&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Peptide Status Detection&lt;/strong&gt;: [Work done at MIT, Manipal with &lt;em&gt;&lt;a class=&quot;tosu&quot; href=&quot;https://www.linkedin.com/in/smitha-nair-2073324a/?ppe=1&quot; target=&quot;_blank&quot;&gt;Prof. Smitha Nair&lt;/a&gt;&lt;/em&gt;] [&lt;a href=&quot;https://github.com/dhawaljoh/PeptideStatusDetection&quot; target=&quot;_blank&quot;&gt;code&lt;/a&gt;] &lt;br /&gt;
Work on detecting Fibrous regions in proteins using the UniProtKB/Swiss-Prot data. Used Support Vector Machines and Bee Colony Optimization for PCA.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ul style=&quot;text-align: justify;&quot;&gt;
  &lt;li&gt;&lt;strong&gt;Data Science London + Scikit-learn&lt;/strong&gt;: [&lt;a href=&quot;https://github.com/dhawaljoh/kaggle--data-science-london&quot; target=&quot;_blank&quot;&gt;code&lt;/a&gt;] &lt;br /&gt;
Kaggle competition to explore sklearn.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 15 Dec 2019 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/2019/projects/</link>
        <guid isPermaLink="true">http://localhost:4000/2019/projects/</guid>
        
        
      </item>
    
  </channel>
</rss>
